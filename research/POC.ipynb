{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GooglePalm\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "import os\n",
    "import pinecone\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "load_dotenv()\n",
    "\n",
    "index_name = os.environ['INDEX_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "# pinecone.init(os.environ['PINECONE_API_KEY'],os.environ['PINECONE_ENV'])\n",
    "print(pc.list_indexes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_name not in pc.list_indexes:\n",
    "    pc.create_index(spec= {'pod': {'environment': 'gcp-starter',\n",
    "                  'pod_type': 'starter',\n",
    "                  'pods': 1,\n",
    "                  'replicas': 1,\n",
    "                  'shards': 1}},name=index_name,dimension=3,metric=\"cosine\")\n",
    "    print(\"INDEX CREATED SUCCESSFULLY ===========!!!!!!!!!!!!!!!!!!!\")\n",
    "else:\n",
    "    print(\"======= Index already exists =========\",pc.describe_index(index_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    {\"id\": \"doc3\", \"values\": [0.7, 0.2, 0.3]},  # Replace with your actual vector\n",
    "    # Add more data as needed\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into Pinecone\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "index.upsert(data)\n",
    "\n",
    "\n",
    "print(\"Data loaded into Pinecone successfully.!!!!!!!!!!!!!!!!!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pdfplumber\n",
    "import openai\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize OpenAI\n",
    "openai.api_key = OPENAI-KEY\n",
    "MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "# Initialize Pinecone\n",
    "pinecone.init(api_key=PINECONE_API, environment='gcp-starter')\n",
    "\n",
    "# Define the index name\n",
    "index_name = \"hs-codes\"\n",
    "\n",
    "# Create the index if it doesn't exist\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(index_name, dimension=1536)\n",
    "\n",
    "# Instantiate the index\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# Define a function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Replace consecutive spaces, newlines and tabs\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def process_pdf(file_path):\n",
    "    # create a loader\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    # load your data\n",
    "    data = loader.load()\n",
    "    # Split your data up into smaller documents with Chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    documents = text_splitter.split_documents(data)\n",
    "    # Convert Document objects into strings\n",
    "    texts = [str(doc) for doc in documents]\n",
    "    return texts\n",
    "\n",
    "# Define a function to create embeddings\n",
    "def create_embeddings(texts):\n",
    "    embeddings_list = []\n",
    "    for text in texts:\n",
    "        res = openai.Embedding.create(input=[text], engine=MODEL)\n",
    "        embeddings_list.append(res['data'][0]['embedding'])\n",
    "    return embeddings_list\n",
    "\n",
    "# Define a function to upsert embeddings to Pinecone\n",
    "def upsert_embeddings_to_pinecone(index, embeddings, ids):\n",
    "    index.upsert(vectors=[(id, embedding) for id, embedding in zip(ids, embeddings)])\n",
    "\n",
    "# Process a PDF and create embeddings\n",
    "file_path = \"your_pdf_here.pdf\"  # Replace with your actual file path\n",
    "texts = process_pdf(file_path)\n",
    "embeddings = create_embeddings(texts)\n",
    "\n",
    "# Upsert the embeddings to Pinecone\n",
    "upsert_embeddings_to_pinecone(index, embeddings, [file_path])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
